Name	DescZh	Desc	Types
deepseek-r1	DeepSeek 的第一代推理模型，在数学、代码和推理任务方面实现了与 OpenAI-o1 相当的性能。	"DeepSeek’s first-generation reasoning models, achieving performance comparable to OpenAI-o1 across math, code, and reasoning tasks."	"1.5b,7b,8b,14b,32b,70b,671b"
qwen2.5-coder	最新系列的特定于代码的 Qwen 模型，在代码生成、代码推理和代码修复方面有重大改进。	"The latest series of Code-Specific Qwen models, with significant improvements in code generation, code reasoning, and code fixing."	"0.5b,1.5b,3b,14b,32b"
qwen2	Qwen2 是阿里巴巴集团推出的一系列新的大型语言模型	Qwen2 is a new series of large language models from Alibaba group	"0.5b,1.5b,7b,72b"
gemma	Gemma 是由 Google DeepMind 构建的一系列轻量级、最先进的开放模型。	"Gemma is a family of lightweight, state-of-the-art open models built by Google DeepMind."	"2b,7b,7b-instruct-fp16"
llama2	Llama 2 是基础语言模型的集合，参数范围从 7B 到 70B。	Llama 2 is a collection of foundation language models ranging from 7B to 70B parameters.	
mistral	Mistral AI 发布的 7B 模型，更新到 0.2 版本。	"The 7B model released by Mistral AI, updated to version 0.2."	
mixtral	Mistral AI 的高质量专家混合 （MoE） 模型，带有开放权重。	A high-quality Mixture of Experts (MoE) model with open weights by Mistral AI.	
llava	� LLaVA 是一种新颖的端到端训练大型多模态模型，它结合了视觉编码器和 Vicuna 以实现通用视觉和语言理解。已更新至版本 1.6。	� LLaVA is a novel end-to-end trained large multimodal model that combines a vision encoder and Vicuna for general-purpose visual and language understanding. Updated to version 1.6.	
neural-chat	基于Mistral的微调模型，对领域和语言有很好的覆盖。	A fine-tuned model based on Mistral with good coverage of domain and language.	
codellama	可以使用文本提示生成和讨论代码的大型语言模型。	A large language model that can use text prompts to generate and discuss code.	
dolphin-mixtral	一个未经审查的微调模型，基于专家混合模型，擅长编码任务。由埃里克·哈特福德（Eric Hartford）创建。	"An uncensored, fine-tuned model based on the Mixtral mixture of experts model that excels at coding tasks. Created by Eric Hartford."	
mistral-openorca	Mistral OpenOrca 是一个 70 亿参数模型，使用 OpenOrca 数据集在 Mistral 7B 模型的基础上进行了微调。	"Mistral OpenOrca is a 7 billion parameter model, fine-tuned on top of the Mistral 7B model using the OpenOrca dataset."	
mistral-openorca	Mistral OpenOrca 是一个 70 亿参数模型，使用 OpenOrca 数据集在 Mistral 7B 模型的基础上进行了微调。	"Mistral OpenOrca is a 7 billion parameter model, fine-tuned on top of the Mistral 7B model using the OpenOrca dataset."	
llama2-uncensored	George Sung 和 Jarrad Hope 的未经审查的 Llama 2 模型。	Uncensored Llama 2 model by George Sung and Jarrad Hope.	
phi	Phi-2：Microsoft Research 的 2.7B 语言模型，展示了出色的推理和语言理解能力。	Phi-2: a 2.7B language model by Microsoft Research that demonstrates outstanding reasoning and language understanding capabilities.	
orca-mini	从30亿个参数到700亿个参数的通用模型，适用于入门级硬件。	"A general-purpose model ranging from 3 billion parameters to 70 billion, suitable for entry-level hardware."	
deepseek-coder	DeepSeek Coder 是一个功能强大的编码模型，在 2 万亿个代码和自然语言令牌上训练。	DeepSeek Coder is a capable coding model trained on two trillion code and natural language tokens.	"6.7b,33b"
dolphin-mistral	基于 Mistral 的未经审查的 Dolphin 模型，擅长编码任务。已更新至版本 2.6。	The uncensored Dolphin model based on Mistral that excels at coding tasks. Updated to version 2.6.	
wizard-vicuna-uncensored	Wizard Vicuna Uncensored 是基于 Eric Hartford 未经审查的 Llama 2 的 7B、13B 和 30B 参数模型。	"Wizard Vicuna Uncensored is a 7B, 13B, and 30B parameter model based on Llama 2 uncensored by Eric Hartford."	"7b, 7b-q4_0,13b, 13b-q4_0,30b, 30b-q4_0"
vicuna	基于 Llama 和 Llama 2 的通用聊天模型，上下文大小为 2K 到 16K。	General use chat model based on Llama and Llama 2 with 2K to 16K context sizes.	
qwen	Qwen 1.5 是阿里云推出的一系列大型语言模型，参数从 0.5B 到 72B 不等	Qwen 1.5 is a series of large language models by Alibaba Cloud spanning from 0.5B to 72B parameters	
zephyr	Zephyr beta 是 mistral 的微调 7B 版本，在公开可用的合成数据集上进行了训练。	"Zephyr beta is a fine-tuned 7B version of mistral that was trained on on a mix of publicly available, synthetic datasets."	
openhermes	OpenHermes 2.5 是一个 7B 模型，由 Teknium 在 Mistral 上微调，具有完全开放的数据集。	OpenHermes 2.5 is a 7B model fine-tuned by Teknium on Mistral with fully open datasets.	
wizardcoder	最先进的代码生成模型	State-of-the-art code generation model	
llama2-chinese	基于Llama 2的模型进行了微调，以提高中文对话能力。	Llama 2 based model fine tuned to improve Chinese dialogue ability.	
tinyllama	TinyLlama 项目是一项公开尝试，旨在在 3 万亿个代币上训练紧凑的 1.1B Llama 模型。	The TinyLlama project is an open endeavor to train a compact 1.1B Llama model on 3 trillion tokens.	
phind-codellama	基于Code Llama的代码生成模型。	Code generation model based on Code Llama.	
openchat	一系列基于各种数据进行训练的开源模型，在各种基准测试中都超过了 ChatGPT。已更新至 3.5-0106 版。	"A family of open-source models trained on a wide variety of data, surpassing ChatGPT on various benchmarks. Updated to version 3.5-0106."	
orca2	Orca 2 由 Microsoft Research 构建，是 Meta 的 Llama 2 模型的微调版本。该模型旨在特别擅长推理。	"Orca 2 is built by Microsoft research, and are a fine-tuned version of Meta's Llama 2 models. The model is designed to excel particularly in reasoning."	
falcon	由技术创新研究所 （TII） 构建的大型语言模型，用于摘要、文本生成和聊天机器人。	"A large language model built by the Technology Innovation Institute (TII) for use in summarization, text generation, and chat bots."	
tinydolphin	Eric Hartford 在新的 Dolphin 2.8 数据集上训练的实验性 1.1B 参数模型，基于 TinyLlama。	An experimental 1.1B parameter model trained on the new Dolphin 2.8 dataset by Eric Hartford and based on TinyLlama.	
wizard-math	专注于数学和逻辑问题的模型	Model focused on math and logic problems	
nous-hermes	基于 Nous Research 的 Llama 和 Llama 2 的通用模型。	General use models based on Llama and Llama 2 from Nous Research.	"7b, 7b-llama2, 7b-llama2-q4_0,13b, 13b-llama2, 13b-llama2-q4_0"
yi	高性能的双语语言模型。	"A high-performing, bilingual language model."	
dolphin-phi	Eric Hartford 的 2.7B 未经审查的 Dolphin 模型，基于 Microsoft Research 的 Phi 语言模型。	"2.7B uncensored Dolphin model by Eric Hartford, based on the Phi language model by Microsoft Research."	
starling-lm	Starling 是一种大型语言模型，通过从 AI 反馈中强化学习来训练，专注于提高聊天机器人的帮助性。	Starling is a large language model trained by reinforcement learning from AI feedback focused on improving chatbot helpfulness.	
starcoder	StarCoder 是一个在 80+ 种编程语言上训练的代码生成模型。	StarCoder is a code generation model trained on 80+ programming languages.	
codeup	基于 Llama2 的出色代码生成模型。	Great code generation model based on Llama2.	"13b, 13b-llama2, 13b-llama2-chat, 13b-llama2-chat-q4_0"
medllama2	微调的 Llama 2 模型，用于回答基于开源医学数据集的医学问题。	Fine-tuned Llama 2 model to answer medical questions based on an open source medical dataset.	
stable-code	Stable Code 3B 是一种提供准确且响应迅速的代码完成的模型，其水平与 CodeLLaMA 7B 等模型相当，后者比 CodeLLaMA 7B 大 2.5 倍。	Stable Code 3B is a model offering accurate and responsive code completion at a level on par with models such as CodeLLaMA 7B that are 2.5x larger.	
bakllava	BakLLaVA 是一种多模态模型，由 Mistral 7B 基本模型组成，并增强了 LLaVA 架构。	BakLLaVA is a multimodal model consisting of the Mistral 7B base model augmented with the LLaVA architecture.	
wizardlm-uncensored	未经审查的 Wizard LM 模型版本	Uncensored version of Wizard LM model	"13b,13b-llama2,13b-llama2-q4_0"
everythinglm	基于 Llama2 的未经审查的模型，支持 16K 上下文窗口。	Uncensored Llama2 based model with support for a 16K context window.	
solar 太阳的	紧凑而强大的 10.7B 大型语言模型，专为单轮对话而设计。	"A compact, yet powerful 10.7B large language model designed for single-turn conversation."	
stable-beluga	基于 Llama 2 的模型在 Orca 风格的数据集上进行了微调。原名Free Willy。	Llama 2 based model fine tuned on an Orca-style dataset. Originally called Free Willy.	
sqlcoder	SQLCoder 是一个代码完成模型，在 StarCoder 上针对 SQL 生成任务进行了微调	SQLCoder is a code completion model fined-tuned on StarCoder for SQL generation tasks	
yarn-mistral	Mistral 的扩展，支持 64K 或 128K 的上下文窗口。	An extension of Mistral to support context windows of 64K or 128K.	7b-128k
nous-hermes2-mixtral	Nous Research 的 Nous Hermes 2 模型，现在在 Mixtral 上进行了训练。	"The Nous Hermes 2 model from Nous Research, now trained over Mixtral."	
samantha-mistral	在哲学、心理学和人际关系方面接受过培训的同伴助理。基于米斯特拉尔。	"A companion assistant trained in philosophy, psychology, and personal relationships. Based on Mistral."	
meditron	从Llama 2改编到医疗领域的开源医疗大语言模型。	Open-source medical large language model adapted from Llama 2 to the medical domain.	
stablelm-zephyr	一种轻量级的聊天模型，无需高端硬件即可实现准确且响应迅速的输出。	"A lightweight chat model allowing accurate, and responsive output without requiring high-end hardware."	
stablelm2	Stable LM 2 1.6B 是一种最先进的 16 亿参数小语言模型，基于英语、西班牙语、德语、意大利语、法语、葡萄牙语和荷兰语的多语言数据进行训练。	"Stable LM 2 1.6B is a state-of-the-art 1.6 billion parameter small language model trained on multilingual data in English, Spanish, German, Italian, French, Portuguese, and Dutch."	
wizard-vicuna	Wizard Vicuna 是一个基于 Llama 2 的 13B 参数模型，由 MelodysDreamj 训练。	Wizard Vicuna is a 13B parameter model based on Llama 2 trained by MelodysDreamj.	
magicoder 	� Magicoder 是一系列 7B 参数模型，使用 OSS-Instruct 在 75K 合成指令数据上进行训练，OSS-Instruct 是一种使用开源代码片段启发 LLM 的新方法。	"� Magicoder is a family of 7B parameter models trained on 75K synthetic instruction data using OSS-Instruct, a novel approach to enlightening LLMs with open-source code snippets."	
yarn-llama2	Llama 2 的扩展，支持多达 128k 个代币的上下文。	An extension of Llama 2 that supports a context of up to 128k tokens.	7b-128k
nous-hermes2	Nous Research 强大的模型系列，擅长科学讨论和编码任务。	The powerful family of models by Nous Research that excels at scientific discussion and coding tasks.	"10.7b,34b"
deepseek-llm	使用 2 万亿个双语令牌制作的高级语言模型。	An advanced language model crafted with 2 trillion bilingual tokens.	
llama-pro	Llama 2 的扩展，专门整合一般语言理解和特定领域的知识，特别是在编程和数学方面。	"An expansion of Llama 2 that specializes in integrating both general language understanding and domain-specific knowledge, particularly in programming and mathematics."	
open-orca-platypus2	Open Orca OpenChat 模型和 Garage-bAInd Platypus 2 模型的合并。专为聊天和代码生成而设计。	Merge of the Open Orca OpenChat model and the Garage-bAInd Platypus 2 model. Designed for chat and code generation.	"13b,13b-q4_0"
codebooga	通过合并两个现有代码模型创建的高性能代码指令模型。	A high-performing code instruct model created by merging two existing code models.	
mistrallite	MistralLite 是基于 Mistral 的微调模型，具有增强的处理长上下文的能力。	MistralLite is a fine-tuned model based on Mistral with enhanced capabilities of processing long contexts.	
nexusraven	Nexus Raven 是用于函数调用任务的 13B 指令调优模型。	Nexus Raven is a 13B instruction tuned model for function calling tasks.	
nomic-embed-text	具有大型令牌上下文窗口的高性能开放式嵌入模型。	A high-performing open embedding model with a large token context window.	
goliath	通过将两个经过微调的 Llama 2 70B 模型组合成一个而创建的语言模型。	A language model created by combining two fine-tuned Llama 2 70B models into one.	
notux	性能最佳的专家模型组合，使用高质量数据进行微调。	"A top-performing mixture of experts model, fine-tuned with high-quality data."	
alfred	一个强大的对话模型，旨在用于聊天和指导用例。	A robust conversational model designed to be used for both chat and instruct use cases.	
megadolphin	MegaDolphin-2.2-120b 是 Dolphin-2.2-70b 的转换，通过将模型与自身交错而创建。	MegaDolphin-2.2-120b is a transformation of Dolphin-2.2-70b created by interleaving the model with itself.	
xwinlm	基于 Llama 2 的对话模型，在各种基准测试中都具有竞争力。	Conversational model based on Llama 2 that performs competitively on various benchmarks.	
wizardlm	通用基于Llama 2的700亿参数模型。	General use 70 billion parameter model based on Llama 2.	
notus	一个7B聊天模型，使用高质量数据进行微调，并基于Zephyr。	A 7B chat model fine-tuned with high-quality data and based on Zephyr.	
duckdb-nsql	由 MotherDuck 和 Numbers Station 制作的 7B 参数文本到 SQL 模型。	7B parameter text-to-SQL model made by MotherDuck and Numbers Station.	
all-minilm	在非常大的句子级数据集上嵌入模型。	Embedding models on very large sentence level datasets.	
starcoder2	StarCoder2 是下一代经过透明训练的开放代码 LLM，有三种大小：3B、7B 和 15B 参数。	"StarCoder2 is the next generation of transparently trained open code LLMs that comes in three sizes: 3B, 7B and 15B parameters."	"3b,7b,15b"
